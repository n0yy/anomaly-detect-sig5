{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PfZb-uQwLAXk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "import time\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oXKEVWKLAXn"
      },
      "source": [
        "# Real Time Anomaly Detection\n",
        "Fungsi untuk mendeteksi anomali secara real-time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Iuh06F18LAXp"
      },
      "outputs": [],
      "source": [
        "def real_time_anomaly_detection(model_path, scaler_path, data_path, threshold, interval=5, max_iterations=100):\n",
        "    # Memuat model dan scaler\n",
        "    model = load_model(model_path, compile=False)\n",
        "    scaler = joblib.load(scaler_path)\n",
        "\n",
        "    # Mengidentifikasi fitur yang digunakan model\n",
        "    features = [col for col in pd.read_csv(data_path).columns\n",
        "                if col not in ['id', 'timestamp', 'reconstruction_error', 'is_anomaly']]\n",
        "\n",
        "    # Inisialisasi dataframe untuk melacak anomali\n",
        "    anomaly_tracking = pd.DataFrame(columns=['timestamp', 'anomaly_count', 'total_samples', 'anomaly_percentage'])\n",
        "\n",
        "    # Mulai deteksi anomali real-time\n",
        "    print(\"Memulai deteksi anomali real-time...\")\n",
        "    for i in range(max_iterations):\n",
        "        # Timestamp saat ini\n",
        "        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        # Memuat data terbaru\n",
        "        df = pd.read_csv(data_path)\n",
        "\n",
        "        # Mendeteksi anomali\n",
        "        X = df[features]\n",
        "        X_scaled = scaler.transform(X)\n",
        "        X_pred = model.predict(X_scaled)\n",
        "        mse = np.mean(np.power(X_scaled - X_pred, 2), axis=1)\n",
        "\n",
        "        # Menambahkan hasil ke dataframe\n",
        "        df['reconstruction_error'] = mse\n",
        "        df['is_anomaly'] = mse > threshold\n",
        "\n",
        "        # Menghitung jumlah anomali dan persentase\n",
        "        anomaly_count = df['is_anomaly'].sum()\n",
        "        total_samples = len(df)\n",
        "        anomaly_percentage = (anomaly_count / total_samples) * 100\n",
        "\n",
        "        # Mencatat statistik anomali\n",
        "        anomaly_tracking = pd.concat([\n",
        "            anomaly_tracking,\n",
        "            pd.DataFrame({\n",
        "                'timestamp': [timestamp],\n",
        "                'anomaly_count': [anomaly_count],\n",
        "                'total_samples': [total_samples],\n",
        "                'anomaly_percentage': [anomaly_percentage]\n",
        "            })\n",
        "        ], ignore_index=True)\n",
        "\n",
        "        # Menampilkan hasil\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Iterasi {i+1}/{max_iterations} - {timestamp}\")\n",
        "        print(f\"Total sampel: {total_samples}\")\n",
        "        print(f\"Anomali terdeteksi: {anomaly_count} ({anomaly_percentage:.2f}%)\")\n",
        "\n",
        "        # Menampilkan sampel anomali terbaru\n",
        "        if anomaly_count > 0:\n",
        "            print(\"\\nSampel anomali terbaru:\")\n",
        "            anomalies = df[df['is_anomaly'] == True].sort_values('reconstruction_error', ascending=False).head(5)\n",
        "            display(anomalies[['id', 'created_date', 'created_time', 'reconstruction_error']])\n",
        "\n",
        "        # Visualisasi tren anomali\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(anomaly_tracking['timestamp'], anomaly_tracking['anomaly_percentage'], marker='o')\n",
        "        plt.title('Tren Persentase Anomali')\n",
        "        plt.xlabel('Waktu')\n",
        "        plt.ylabel('Persentase Anomali (%)')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Visualisasi distribusi error rekonstruksi\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.histplot(df['reconstruction_error'], bins=30)\n",
        "        plt.axvline(x=threshold, color='r', linestyle='--', label=f'Threshold: {threshold:.6f}')\n",
        "        plt.title('Distribusi Reconstruction Error')\n",
        "        plt.xlabel('Reconstruction Error (MSE)')\n",
        "        plt.ylabel('Jumlah Sampel')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Jika bukan iterasi terakhir, tunggu sebelum iterasi berikutnya\n",
        "        if i < max_iterations - 1:\n",
        "            print(f\"\\nMenunggu {interval} detik untuk pengambilan data berikutnya...\")\n",
        "            time.sleep(interval)\n",
        "\n",
        "    print(\"Deteksi anomali real-time selesai.\")\n",
        "    return anomaly_tracking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anomaly_stats = real_time_anomaly_detection(\n",
        "    model_path='anomaly_autoencoder_model.h5',\n",
        "    scaler_path='anomaly_scaler.pkl',\n",
        "    data_path='tb_sig_5.csv',\n",
        "    threshold=0.01,  # Sesuaikan dengan nilai threshold yang diperoleh dari model\n",
        "    interval=10,\n",
        "    max_iterations=20\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "QPjJ2LUZLMkm",
        "outputId": "d7978d8d-0bd0-4a08-eb33-7f4543099e0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai deteksi anomali real-time...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- created_date\n- created_time\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e1e97dab1379>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m anomaly_stats = real_time_anomaly_detection(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'anomaly_autoencoder_model.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mscaler_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'anomaly_scaler.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tb_sig_5.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Sesuaikan dengan nilai threshold yang diperoleh dari model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-946815ced2c7>\u001b[0m in \u001b[0;36mreal_time_anomaly_detection\u001b[0;34m(model_path, scaler_path, data_path, threshold, interval, max_iterations)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Mendeteksi anomali\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mX_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2918\u001b[0m     \"\"\"\n\u001b[0;32m-> 2919\u001b[0;31m     \u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2920\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2775\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Feature names must be in the same order as they were in fit.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- created_date\n- created_time\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NbihWQm-LZp2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}