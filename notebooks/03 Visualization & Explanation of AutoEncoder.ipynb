{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(model_path, scaler_path, data_path):\n",
    "    # Memuat model dan scaler\n",
    "    model = load_model(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    # Memuat data\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Mengidentifikasi fitur yang digunakan model\n",
    "    features = [col for col in df.columns \n",
    "                if col not in ['id', 'created_date', 'created_time', 'reconstruction_error', 'is_anomaly']]\n",
    "    \n",
    "    # Jika hasil deteksi belum ada di data, lakukan deteksi\n",
    "    if 'reconstruction_error' not in df.columns or 'is_anomaly' not in df.columns:\n",
    "        # Preprocessing\n",
    "        X = df[features]\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "        # Prediksi\n",
    "        X_pred = model.predict(X_scaled)\n",
    "        \n",
    "        # Hitung rekonstruksi error\n",
    "        mse = np.mean(np.power(X_scaled - X_pred, 2), axis=1)\n",
    "        \n",
    "        # Tentukan threshold (contoh: 95th percentile)\n",
    "        threshold = np.percentile(mse, 95)\n",
    "        \n",
    "        # Tambahkan hasil ke dataframe\n",
    "        df['reconstruction_error'] = mse\n",
    "        df['is_anomaly'] = mse > threshold\n",
    "    \n",
    "    return model, scaler, df, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly vs normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_normal_vs_anomaly(df, features):\n",
    "    \"\"\"\n",
    "    Visualisasi distribusi data normal vs anomali untuk fitur-fitur utama.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame dengan kolom is_anomaly\n",
    "        features (list): Daftar fitur yang akan divisualisasikan\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Pilih 8 fitur teratas untuk visualisasi\n",
    "    visual_features = features[:8]\n",
    "    \n",
    "    for i, feature in enumerate(visual_features):\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        sns.kdeplot(df[df['is_anomaly'] == False][feature], label='Normal', color='blue')\n",
    "        sns.kdeplot(df[df['is_anomaly'] == True][feature], label='Anomali', color='red')\n",
    "        plt.title(f'Distribusi {feature}')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Perbandingan Distribusi Fitur: Normal vs Anomali', fontsize=16, y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization with Dimentionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_with_dimension_reduction(df, features, scaler):\n",
    "    \"\"\"\n",
    "    Visualisasi data menggunakan PCA dan t-SNE untuk melihat clustering anomali.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame dengan kolom is_anomaly\n",
    "        features (list): Daftar fitur untuk reduksi dimensi\n",
    "        scaler: Scaler yang digunakan untuk normalisasi data\n",
    "    \"\"\"\n",
    "    # Ekstrak dan normalisasi data fitur\n",
    "    X = df[features]\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # PCA untuk reduksi dimensi\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # t-SNE untuk reduksi dimensi\n",
    "    tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "    X_tsne = tsne.fit_transform(X_scaled)\n",
    "    \n",
    "    # Visualisasi hasil PCA\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['is_anomaly'], cmap='coolwarm', alpha=0.7)\n",
    "    plt.title('PCA: Normal vs Anomali')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.colorbar(scatter, label='Anomali')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=df['is_anomaly'], cmap='coolwarm', alpha=0.7)\n",
    "    plt.title('t-SNE: Normal vs Anomali')\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.colorbar(scatter, label='Anomali')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Menampilkan explained variance PCA\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(f\"Explained variance by PCA components: {explained_variance[0]:.4f}, {explained_variance[1]:.4f}\")\n",
    "    print(f\"Total explained variance: {sum(explained_variance):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Anomaly Pattern time-by-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_temporal_patterns(df):\n",
    "    \"\"\"\n",
    "    Analisis pola anomali berdasarkan waktu.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame dengan timestamp dan kolom is_anomaly\n",
    "    \"\"\"\n",
    "    # Pastikan format waktu tepat\n",
    "    if 'created_date' in df.columns and 'created_time' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['created_date'] + ' ' + df['created_time'])\n",
    "    \n",
    "    # Mengelompokkan anomali berdasarkan tanggal\n",
    "    if 'timestamp' in df.columns:\n",
    "        # Ekstrak tanggal dari timestamp\n",
    "        df['date'] = df['timestamp'].dt.date\n",
    "        \n",
    "        # Hitung jumlah anomali per tanggal\n",
    "        anomaly_by_date = df.groupby('date')['is_anomaly'].sum().reset_index()\n",
    "        anomaly_by_date.columns = ['date', 'anomaly_count']\n",
    "        \n",
    "        # Hitung total sampel per tanggal\n",
    "        total_by_date = df.groupby('date').size().reset_index()\n",
    "        total_by_date.columns = ['date', 'total_count']\n",
    "        \n",
    "        # Gabungkan untuk menghitung persentase\n",
    "        anomaly_stats = pd.merge(anomaly_by_date, total_by_date, on='date')\n",
    "        anomaly_stats['anomaly_percentage'] = (anomaly_stats['anomaly_count'] / anomaly_stats['total_count']) * 100\n",
    "        \n",
    "        # Visualisasi tren anomali\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.bar(range(len(anomaly_stats)), anomaly_stats['anomaly_percentage'], \n",
    "                width=0.4, color='skyblue', edgecolor='darkblue')\n",
    "        plt.xticks(range(len(anomaly_stats)), [d.strftime('%Y-%m-%d') for d in anomaly_stats['date']], rotation=45)\n",
    "        plt.title('Persentase Anomali per Tanggal')\n",
    "        plt.xlabel('Tanggal')\n",
    "        plt.ylabel('Persentase Anomali (%)')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return anomaly_stats\n",
    "    else:\n",
    "        print(\"Informasi waktu tidak tersedia dalam data.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of features that contribute most to anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_contribution(df, model, scaler, features):\n",
    "    \"\"\"\n",
    "    Analisis kontribusi setiap fitur terhadap anomali.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): DataFrame dengan kolom is_anomaly\n",
    "        model: Model autoencoder yang dilatih\n",
    "        scaler: Scaler yang digunakan untuk normalisasi data\n",
    "        features (list): Daftar fitur yang dianalisis\n",
    "    \"\"\"\n",
    "    # Ekstrak data anomali dan normal\n",
    "    anomaly_data = df[df['is_anomaly'] == True][features]\n",
    "    normal_data = df[df['is_anomaly'] == False][features]\n",
    "    \n",
    "    # Normalisasi data\n",
    "    anomaly_scaled = scaler.transform(anomaly_data)\n",
    "    normal_scaled = scaler.transform(normal_data)\n",
    "    \n",
    "    # Prediksi rekonstruksi\n",
    "    anomaly_pred = model.predict(anomaly_scaled)\n",
    "    normal_pred = model.predict(normal_scaled)\n",
    "    \n",
    "    # Hitung error per fitur\n",
    "    anomaly_error_per_feature = np.mean(np.power(anomaly_scaled - anomaly_pred, 2), axis=0)\n",
    "    normal_error_per_feature = np.mean(np.power(normal_scaled - normal_pred, 2), axis=0)\n",
    "    \n",
    "    # Hitung rasio error (anomali / normal) untuk mengidentifikasi fitur yang paling kontributif\n",
    "    error_ratio = anomaly_error_per_feature / (normal_error_per_feature + 1e-10)\n",
    "    \n",
    "    # Buat DataFrame untuk visualisasi\n",
    "    feature_contribution = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'anomaly_error': anomaly_error_per_feature,\n",
    "        'normal_error': normal_error_per_feature,\n",
    "        'error_ratio': error_ratio\n",
    "    }).sort_values('error_ratio', ascending=False)\n",
    "    \n",
    "    # Visualisasi kontribusi fitur\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='error_ratio', y='feature', data=feature_contribution, palette='viridis')\n",
    "    plt.title('Kontribusi Fitur terhadap Anomali (Rasio Error Anomali/Normal)')\n",
    "    plt.xlabel('Rasio Error (Anomali / Normal)')\n",
    "    plt.ylabel('Fitur')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(model_path, scaler_path, data_path):\n",
    "    \"\"\"\n",
    "    Menjalankan seluruh analisis dan visualisasi.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path ke model yang disimpan\n",
    "        scaler_path (str): Path ke scaler yang disimpan\n",
    "        data_path (str): Path ke data yang akan dianalisis\n",
    "    \"\"\"\n",
    "    # Memuat model, scaler, dan data\n",
    "    model, scaler, df, features = load_results(model_path, scaler_path, data_path)\n",
    "    \n",
    "    # Visualisasi distribusi normal vs anomali\n",
    "    visualize_normal_vs_anomaly(df, features)\n",
    "    \n",
    "    # Visualisasi dengan reduksi dimensi (PCA dan t-SNE)\n",
    "    visualize_with_dimension_reduction(df, features, scaler)\n",
    "    \n",
    "    # Analisis pola anomali dari waktu ke waktu\n",
    "    anomaly_stats = analyze_temporal_patterns(df)\n",
    "    \n",
    "    # Analisis kontribusi fitur terhadap anomali\n",
    "    feature_contribution = analyze_feature_contribution(df, model, scaler, features)\n",
    "    \n",
    "    return anomaly_stats, feature_contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Path ke model, scaler, dan data\n",
    "    model_path = 'autoencoder_model.h5'\n",
    "    scaler_path = 'scaler.pkl'\n",
    "    data_path = 'data_with_results.csv'\n",
    "    \n",
    "    # Jalankan analisis\n",
    "    anomaly_stats, feature_contribution = run_analysis(model_path, scaler_path, data_path)\n",
    "    \n",
    "    # Tampilkan hasil analisis\n",
    "    print(\"\\nStatistik Anomali per Tanggal:\")\n",
    "    print(anomaly_stats)\n",
    "    \n",
    "    print(\"\\nKontribusi Fitur terhadap Anomali:\")\n",
    "    print(feature_contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
